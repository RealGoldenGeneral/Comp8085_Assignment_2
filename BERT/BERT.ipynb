{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e49d686d-b75e-406a-8c71-28e2dddc06a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Store the dataset and subsample it\n",
    "import pandas as pd\n",
    "chunk_array = []\n",
    "with pd.read_json(\"../yelp_academic_dataset_review.json\", orient=\"records\", lines=True, chunksize=40000) as reader:\n",
    "    for chunk in reader:\n",
    "        chunk_array.append(chunk)\n",
    "raw_dataset = chunk_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e56f7b0-4e1f-4d15-bb91-23d23ee45c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    review_id                 user_id             business_id  \\\n",
      "0      KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
      "1      BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
      "2      saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
      "3      AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
      "4      Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
      "...                       ...                     ...                     ...   \n",
      "39995  EYkouQA9oWuiWDNZsYl7aA  WfiilB5OXV7vSmHP-80n-A  HQ-C47_Xi5it1KzwEc0u0A   \n",
      "39996  xZi6gbagKAzqCKjtDLrhGQ  BDEi5eV-uhP4A4atMNzW5w  ena3aLdMz2ym_OPVuTIJ2g   \n",
      "39997  bxEjtoD74xPBJnMtV2759A  GLCcS7HGPa7MD997xq5W9w  34Eqv8jXgxg_EEwcsNgeeg   \n",
      "39998  xT8DOnqIu_7N-9AnkFftaQ  bNnBwW5kNO77KTgMeVhxKg  F2C5ENuY8CXfgoW-gAMdDA   \n",
      "39999  Wy7Njv1S0SaLEk9Bj-ZHPw  ZVREpaL2TPWMtUDJaUZulg  ORL4JE6tz3rJxVqkdKfegA   \n",
      "\n",
      "       stars  useful  funny  cool  \\\n",
      "0          3       0      0     0   \n",
      "1          5       1      0     1   \n",
      "2          3       0      0     0   \n",
      "3          5       1      0     1   \n",
      "4          4       1      0     1   \n",
      "...      ...     ...    ...   ...   \n",
      "39995      4       0      0     0   \n",
      "39996      5       4      1     2   \n",
      "39997      4       1      0     0   \n",
      "39998      3       0      0     0   \n",
      "39999      3       0      0     0   \n",
      "\n",
      "                                                    text                date  \n",
      "0      If you decide to eat here, just be aware it is... 2018-07-07 22:09:11  \n",
      "1      I've taken a lot of spin classes over the year... 2012-01-03 15:28:18  \n",
      "2      Family diner. Had the buffet. Eclectic assortm... 2014-02-05 20:30:30  \n",
      "3      Wow!  Yummy, different,  delicious.   Our favo... 2015-01-04 00:01:03  \n",
      "4      Cute interior and owner (?) gave us tour of up... 2017-01-14 20:54:15  \n",
      "...                                                  ...                 ...  \n",
      "39995  Late night, kind of pricey pizza but good for ... 2015-07-07 19:13:32  \n",
      "39996  Tony Blanche, owner of the Clam Tavern, has op... 2012-01-07 21:46:58  \n",
      "39997  a very interesting change of pace for breakfas... 2016-08-27 15:42:30  \n",
      "39998  This place is just \"OK\" in my book. I'll go if... 2017-05-28 23:58:04  \n",
      "39999  Stayed here for a meeting we had at Vanderbilt... 2014-09-13 04:19:46  \n",
      "\n",
      "[40000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d7581e3-fd58-45f7-b953-ca2929a577e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Split dataset into train, validation, and test sets\n",
    "# Manually select portion of dataset\n",
    "train_size = 20000\n",
    "val_size = 30000\n",
    "\n",
    "# Manually slice dataset\n",
    "train_df = raw_dataset.iloc[:train_size]\n",
    "val_df = raw_dataset.iloc[train_size:val_size]\n",
    "test_df = raw_dataset.iloc[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d2b904c-c6ca-4c75-bf29-1c60a7a023b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Tokenize the dataset\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "# Tokenize review texts\n",
    "train_texts = train_df['text'].tolist()\n",
    "val_texts = val_df['text'].tolist()\n",
    "test_texts = test_df['text'].tolist()\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db52b062-e89d-420d-bce9-03891e4c680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4: Extract labels\n",
    "import torch\n",
    "\n",
    "columns = ['stars', 'useful', 'cool', 'funny']\n",
    "\n",
    "train_labels = torch.tensor(train_df[columns].values)\n",
    "val_labels = torch.tensor(val_df[columns].values)\n",
    "test_labels = torch.tensor(test_df[columns].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1550c0eb-c4b6-4e82-af9b-d29098e85968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5: Prepare dataset for PyTorch model\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "# Create custom Dataset class\n",
    "class YelpReviewDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create dataset objects for training, validation, and testing\n",
    "train_dataset = YelpReviewDataset(train_encodings, train_labels)\n",
    "val_dataset = YelpReviewDataset(val_encodings, val_labels)\n",
    "test_dataset = YelpReviewDataset(test_encodings, test_labels)\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4d0c68b-abd0-41fd-8b0f-8d5f06ace181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Part 4: Load pre-trained BERT model\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"google-bert/bert-base-uncased\", num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "773420c2-e795-4745-8214-147bc61184ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 1.6062116950511933\n",
      "Epoch 1 - Validation MSE: 1.252678357814985\n",
      "Epoch 2 - Training loss: 1.3803184407711029\n",
      "Epoch 2 - Validation MSE: 1.232054038737448\n",
      "Epoch 3 - Training loss: 1.287151593375206\n",
      "Epoch 3 - Validation MSE: 1.2381401882235157\n",
      "Epoch 4 - Training loss: 1.1240907793283463\n",
      "Epoch 4 - Validation MSE: 1.3301969455375364\n",
      "Epoch 5 - Training loss: 0.9521248504936695\n",
      "Epoch 5 - Validation MSE: 1.2597644419579592\n",
      "Epoch 6 - Training loss: 0.8160863175392151\n",
      "Epoch 6 - Validation MSE: 1.2916457599198472\n",
      "Epoch 7 - Training loss: 0.7322426264882088\n",
      "Epoch 7 - Validation MSE: 1.2670519048466398\n",
      "Epoch 8 - Training loss: 0.6507497804820538\n",
      "Epoch 8 - Validation MSE: 1.3040661101335322\n",
      "Epoch 9 - Training loss: 0.5950958204627037\n",
      "Epoch 9 - Validation MSE: 1.2808329162835115\n",
      "Epoch 10 - Training loss: 0.552346251487732\n",
      "Epoch 10 - Validation MSE: 1.3178448575156443\n"
     ]
    }
   ],
   "source": [
    "# Part 5: Train the model\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Define loss function (Mean Squared Error for regression)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, labels.float())\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def evaluate(mode, data_loader):\n",
    "    model.eval()\n",
    "    preds, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            preds.append(logits.cpu().numpy())\n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "    # Evaluate using mean squared error\n",
    "    mse = mean_squared_error(true_labels, preds)\n",
    "    return mse\n",
    "\n",
    "# Run training and evaluation for multiple epochs\n",
    "for epoch in range(3): # Adjust the number of epochs as necessary\n",
    "    train_loss = train_epoch(model, train_loader, loss_fn, optimizer)\n",
    "    print(f\"Epoch {epoch + 1} - Training loss: {train_loss}\")\n",
    "\n",
    "    mse = evaluate(model, val_loader)\n",
    "    print(f\"Epoch {epoch + 1} - Validation MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c97fd66-98d9-45cd-82d1-bea80ec02d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on the test set: 1.5290840172460103\n"
     ]
    }
   ],
   "source": [
    "# Part 6: Predict the test set\n",
    "def predict_on_test(model, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            all_preds.append(logits.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            \n",
    "    # Convert list of predictions and labels to numpy arrays\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return all_preds, all_labels\n",
    "\n",
    "# Get predictions on the test set\n",
    "test_preds, test_labels = predict_on_test(model, test_loader)\n",
    "\n",
    "mse = mean_squared_error(test_labels, test_preds)\n",
    "print(f'Mean Squared Error on the test set: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a0ebbfd-3d38-4045-8c09-acc40cc22b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This place is fantastic. I was apprehensive (as I often am walking into bike shops) when I walked in, but quickly realized that this place was different. There were some hard core road bikers in the back talking in their own language, a few weekend warriors getting their bikes worked on and getting gear, and me: an aspiring cyclist intimidated by the prices, lingo, and other details of taking up this pastime.  I normally cringe when I walk into bike stores and feel that if I don't drop 4 grand quickly on a carbon fiber bike or show them the yellow jersey I wore when leading three stages of the Tour de France, that I'll quickly be shown the exit (or a brusque cold shoulder).\n",
      "\n",
      "At this place, a guy came up and asked what I was looking for and how he could help. I explained my situation: I have a road bike, I want to start using it as my primary means of transportation and for recreation, and I want to get the rest of the equipment that I need. He quickly explained what equipment is NEEDED versus what equipment is NICE TO HAVE. We went through helmets, floor pumps, bike shorts, bike shoes, flat kits, etc. I already have shoes and pedals as well as some tire repair kits. When I told him that, he quickly moved on - never pressuring me to upgrade or to change anything. We talked tire options (tube liners/extra-thick tires/tube sealant), tune up needs, maintenance suggestions, etc.\n",
      "\n",
      "In the end, I only bought a helmet because I had all of the gear in the NEED category already. As I get going, I'll add the NICE TO HAVE stuff as I see fit. And I'll buy it from Reno Cycling & Fitness because they know how to treat customers. So it is amazing, for a fairly minor purchase, this guy invested nearly half an hour talking to me - never talking down to me. He understood my needs, listened when i talked and helped me immensely.\n",
      "\n",
      "In a world of diminishing customer service, this place stands out. The depth of knowledge available will not be found in a big box store or at an online discounter. Keep honest, hardworking local companies in business and help yourself in the process.\n",
      "True labels: [5 2 1 0]\n",
      "Predicted labels: [4.3322687  3.2381408  0.90217894 0.24855492]\n",
      "--------------------------------------------------\n",
      "Review: I did not enjoy my food here. The fish was fried so hard I couldn't eat it. My rice taste like some boil n the bag rice. I was not impressed at all.\n",
      "True labels: [1 1 0 0]\n",
      "Predicted labels: [ 1.4832478  -0.08954163 -0.05537903 -0.00189436]\n",
      "--------------------------------------------------\n",
      "Review: The pho is EXCELLENT and so is the service...but it's not the tidiest place in town.  The walls are pretty dirty, which is surprising for a newish place, and the floors are often not clean.  Regardless, it's still my go to pho spot.\n",
      "True labels: [4 0 0 0]\n",
      "Predicted labels: [ 3.4854038  -0.03187297  0.08481123 -0.04975006]\n",
      "--------------------------------------------------\n",
      "Review: Cafe deluxe was awesome. This used to be a laundromat back in the day, and now they've established a quirky little breakfast spot. We got some kind of breakfast scramble with meats and various other veggie ingredients. We ordered some flour tortillas on the side which were huge. \n",
      "\n",
      "The egg scrambles were huge portions, so after we got our fill, I made us two huge burritos to go. \n",
      "\n",
      "Cool place, nice people, and great coffee.\n",
      "True labels: [4 1 1 0]\n",
      "Predicted labels: [ 4.5449977  -0.06480813  0.16732153 -0.02432217]\n",
      "--------------------------------------------------\n",
      "Review: I recently stayed at The Saint with my sister for a few nights and loved it.  The minute we walked in we knew we'd loved it because of the amazing decor and the amazing hospitality. Right from the first time we walked in, we felt so welcome with the doorman and the front desk girls. SUPER!!! FRIENDLY!!! \n",
      "\n",
      "The hotel lobby and entrance all looked cool with great paintings and decor.  Just like their other locations, they have these oversized chairs that are great for taking fun pictures so before we even went up to see our room we already took a ton of cool pictures.  The chairs make you feel so miniature.\n",
      "\n",
      "The hotel also has a really nice bar in the lobby.  It's decorated with lots of red chandeliers hanging over the bar and they serve some really great drinks.  If you're ever there, you need to make sure you go for there happy hours drinks (WAY cheaper).  At night the bar does get pretty busy and every night they have a live band so it was nice to sit and listen to them but it does get a little loud.\n",
      "\n",
      "When we finally decided to go up to our room, we entered the elevator and we were so surprised and thought it was funny that they have a television that is always playing Classic Jazz (how cool is that?).  When the elevator doors open, the entire hallway was all dark with  blue lights; at first it reminded me of the movie The Shinning LOL\n",
      "\n",
      "Our room was really roomy and nice.  At first I didn't like that our room was at the back of the building where you have no view (just looking at another building right there) but later i was happy to be in the back because when you get the rooms along Canal Street it is really loud with all the traffic and street action; the view wasn't worth it so we kept our back room.  But I will say I was so happy that the hotel was willing to change us if we wanted.\n",
      "\n",
      "The location was so good; really close to everything we needed like best spot to get the trolleys, on the edge of the French Quarter, nearby so much more.\n",
      "True labels: [5 5 4 3]\n",
      "Predicted labels: [ 4.6447496   0.2396958  -0.08454649 -0.06606865]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Review: {raw_dataset['text'].iloc[30000 + i]}\")\n",
    "    print(f\"True labels: {test_labels[i]}\")\n",
    "    print(f\"Predicted labels: {test_preds[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49ff1c-f1ce-42fb-99f0-e4c9d2af4503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
